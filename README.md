# Medical Report Generator

Full-Stack Anwendung zur automatischen Generierung strukturierter Arztberichte mit lokalen LLM-Modellen (Ollama). Entwickelt fÃ¼r die digitale Transformation im Gesundheitswesen.

## ğŸ¯ Features

- **Automatische Berichtgenerierung**: Strukturierte Arztberichte aus Patientendaten
- **Lokale LLM-Integration**: Datenschutzkonform mit Ollama (keine Cloud-AbhÃ¤ngigkeit)
- **Full-Stack TypeScript**: Type-safe von Backend bis Frontend
- **Medizinische Standards**: DSGVO-konforme Verarbeitung sensibler Gesundheitsdaten
- **Editierfunktion**: Manuelle Nachbearbeitung generierter Berichte
- **Echtzeit-Validierung**: Strukturierte Eingabe mit Vitalzeichen, Medikation, Allergien

## ğŸ—ï¸ Tech Stack

### Backend
- **Node.js** + **Express** - REST API
- **TypeScript** - Type Safety
- **Ollama API** - Lokale LLM-Integration (Llama 3.2)
- **Axios** - HTTP Client

### Frontend
- **React 18** + **TypeScript**
- **Vite** - Build Tool
- **Axios** - API Communication
- **CSS3** - Responsive Design

## ğŸ“‹ Voraussetzungen

- **Node.js** >= 18.x
- **npm** >= 9.x
- **Ollama** (fÃ¼r lokales LLM)
- **RAM**: Mind. 8GB (fÃ¼r Llama 3.2:3b) oder 16GB (fÃ¼r 8b-Modell)

## ğŸš€ Installation

### 1. Ollama installieren

**Windows:**
```bash
# Download von https://ollama.com/download
# Installiere Ollama
# Starte Ollama und lade Modell:
ollama pull llama3.2:3b
```

**Linux/Mac:**
```bash
curl -fsSL https://ollama.com/install.sh | sh
ollama pull llama3.2:3b
```

### 2. Backend Setup
```bash
cd backend
npm install
npm run dev
```

Backend lÃ¤uft auf: `http://localhost:3001`

### 3. Frontend Setup
```bash
cd frontend
npm install
npm run dev
```

Frontend lÃ¤uft auf: `http://localhost:5173`

### 4. Ollama starten
```bash
ollama serve
```

PrÃ¼fe Status auf: `http://localhost:11434`

## ğŸ“ Projektstruktur
```
medical-report-generator/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ ollamaService.ts      # Ollama API Integration
â”‚   â”‚   â”‚   â””â”€â”€ reportGenerator.ts    # Bericht-Generierung
â”‚   â”‚   â”œâ”€â”€ types.ts                  # TypeScript Typen
â”‚   â”‚   â””â”€â”€ index.ts                  # Express Server
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ tsconfig.json
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ PatientForm.tsx       # Patientendaten-Formular
â”‚   â”‚   â”‚   â””â”€â”€ ReportDisplay.tsx     # Bericht-Anzeige
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ api.ts                # API Client
â”‚   â”‚   â”œâ”€â”€ types.ts                  # TypeScript Typen
â”‚   â”‚   â”œâ”€â”€ App.tsx                   # Haupt-Komponente
â”‚   â”‚   â””â”€â”€ App.css                   # Styling
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ tsconfig.json
â”‚
â””â”€â”€ README.md
```

## ğŸ”§ Konfiguration

### Backend Environment

Erstelle optional `.env` in `backend/`:
```env
PORT=3001
OLLAMA_URL=http://localhost:11434
```

### LLM-Modell wechseln

In `backend/src/services/ollamaService.ts`:
```typescript
model: 'llama3.2:8b',  // FÃ¼r bessere QualitÃ¤t (mehr RAM nÃ¶tig)
```

VerfÃ¼gbare Modelle:
- `llama3.2:3b` - Schnell, 8GB RAM
- `llama3.2:8b` - Bessere QualitÃ¤t, 16GB RAM
- `mistral:7b` - Alternative

## ğŸ“– Verwendung

### 1. Patientendaten eingeben

- **Pflichtfelder**: Patienten-ID, Alter, Diagnose
- **Optional**: Symptome, Vitalzeichen, Medikation, Allergien, Notizen

### 2. Bericht generieren

Klicke auf "Bericht generieren". Die Generierung dauert 30-60 Sekunden.

### 3. Bericht bearbeiten

- Klicke "Bearbeiten" fÃ¼r manuelle Anpassungen
- "Speichern" fÃ¼r Ã„nderungen
- "Drucken" fÃ¼r PDF-Export

## ğŸ§ª Test-Beispiel
```json
{
  "patientId": "P-2024-001",
  "age": 45,
  "gender": "male",
  "symptoms": ["Husten", "Fieber", "Atemnot"],
  "vitalSigns": {
    "bloodPressure": "130/85",
    "heartRate": 88,
    "temperature": 38.5,
    "respiratoryRate": 22
  },
  "diagnosis": "Akute Bronchitis",
  "medications": ["Amoxicillin 500mg 3x tÃ¤glich"],
  "allergies": ["Keine"],
  "notes": "Patient berichtet von Symptombeginn vor 3 Tagen"
}
```

## ğŸ¥ Medizinische Features

### Generierte Berichtsstruktur

1. **Patienteninformationen** - ID, Alter, Geschlecht
2. **Anamnese und Symptomatik** - Symptome, Krankheitsverlauf
3. **Klinische Befunde** - Vitalzeichen, Untersuchungsergebnisse
4. **Diagnose und Beurteilung** - Medizinische EinschÃ¤tzung
5. **Therapie und Medikation** - Behandlungsplan

### DSGVO-Compliance

- Alle Daten bleiben lokal (keine Cloud)
- Keine Speicherung von Patientendaten
- Ollama-Modelle laufen on-premise
- Keine externe API-Calls

## ğŸ” API Endpoints

### Health Check
```http
GET /api/health
```
Response:
```json
{
  "status": "ok",
  "ollama": "connected"
}
```

### Generate Report
```http
POST /api/generate-report
Content-Type: application/json

{
  "patientId": "P-2024-001",
  "age": 45,
  "gender": "male",
  "symptoms": ["Husten"],
  "diagnosis": "Bronchitis",
  ...
}
```

## ğŸ› Troubleshooting

### Ollama nicht erreichbar
```bash
# PrÃ¼fe ob Ollama lÃ¤uft:
ollama list

# Starte Ollama:
ollama serve

# Teste API:
curl http://localhost:11434/api/tags
```

### CORS Fehler
Stelle sicher, dass Backend auf Port 3001 lÃ¤uft und Frontend auf 5173.

### Langsame Generierung
- Nutze kleineres Modell: `llama3.2:3b` statt `8b`
- Reduziere `max_tokens` in `ollamaService.ts`
- PrÃ¼fe CPU/RAM Auslastung

### TypeScript Fehler
```bash
# Backend:
cd backend && npm run build

# Frontend:
cd frontend && npm run build
```

## ğŸš€ Production Build

### Backend
```bash
cd backend
npm run build
npm start
```

### Frontend
```bash
cd frontend
npm run build
# Serve dist/ mit nginx oder serve
```

## ğŸ“ˆ Erweiterungen

MÃ¶gliche weitere Features:
- **ICD-10 Code-Extraktion** mit NLP
- **Medikamenten-Datenbank** Integration
- **PDF-Export** mit Styling
- **Template-System** fÃ¼r verschiedene Berichtstypen
- **Audit-Log** fÃ¼r Ã„nderungen
- **Multi-User** mit Authentifizierung
- **Vector DB** fÃ¼r semantische Suche in Berichten

## ğŸ¤ Entwickelt fÃ¼r

Systeme im Gesundheitswesen

**Technologie-Demonstration fÃ¼r:**
- AI-gestÃ¼tzte klinische Informationssysteme
- Automatisierte Berichtgenerierung
- Lokale LLM-Integration
- Full-Stack TypeScript Development
- DSGVO-konforme AI-LÃ¶sungen

## ğŸ‘¨â€ğŸ’» Autor
JJ
---

**Hinweis**: Dies ist eine Demo-Anwendung. FÃ¼r den Produktiveinsatz im medizinischen Umfeld sind zusÃ¤tzliche Validierungen, Zertifizierungen und SicherheitsmaÃŸnahmen erforderlich.
```

---

## Repository Description (kurz)
```
Full-Stack Medical Report Generator mit lokalen LLMs (Ollama). Automatische Arztbericht-Erstellung aus strukturierten Patientendaten. Node.js + React + TypeScript. DSGVO-konform, keine Cloud.